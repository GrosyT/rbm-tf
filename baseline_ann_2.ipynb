{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#token:\n",
    "#http://127.0.0.1:8888/?token=213d7c96a44367f5295370d6941718325f47032e4a519a21\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import biomag data\n",
    "biomag_labeled_1 = sio.loadmat(r\"D:\\python_project\\wip\\baseline\\data_labeled_for_py_baseline1_1.mat\")\n",
    "#\"lib\": [r\"phd\\orai\\6\\History-From-the-Quaran-to-Bin-Laden_txt.txt\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tanítóhalmaz címkéinek formája:  (2094,)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.1\n",
    "num_steps = 1000\n",
    "batch_size = 128                         # -s         -o 128\n",
    "display_step = 100\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 500 # 1st layer number of neurons\n",
    "n_hidden_2 = 500 # 2nd layer number of neurons\n",
    "num_input = 254 # biomag data input (shape: *)\n",
    "num_classes = 12 # biomag total classes (1-12)\n",
    "\n",
    "#Data preprocessing -s\n",
    "biomag_labeled_1['y_train'] = biomag_labeled_1['y_train'].T\n",
    "\n",
    "biomag_labeled_1['y_train'] = np.reshape(biomag_labeled_1['y_train'],2094)\n",
    "\n",
    "print('Tanítóhalmaz címkéinek formája: ',biomag_labeled_1['y_train'].shape)\n",
    "\n",
    "#y labels -1\n",
    "biomag_labeled_1['y_train'] = biomag_labeled_1['y_train']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 1., 1., 7.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#int(biomag_labeled_1['y_train'][:])\n",
    "biomag_labeled_1['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input function for training\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'train_data': biomag_labeled_1['x_train']}, y=biomag_labeled_1['y_train'],\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "\n",
    "# Define the neural network\n",
    "def neural_net(x_dict):\n",
    "    # TF Estimator input is a dict, in case of multiple inputs\n",
    "    x = x_dict['train_data']\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.layers.dense(x, n_hidden_1, activation= tf.nn.relu)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2, activation= tf.nn.relu)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.layers.dense(layer_2, num_classes)\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    # Build the neural network\n",
    "    logits = neural_net(features)\n",
    "\n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "\n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes)\n",
    "\n",
    "        # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits (              #rank mismatch -s   softmax_cross_entropy_with_logits\n",
    "        logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "\n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "\n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=pred_classes,\n",
    "        loss=loss_op,\n",
    "        train_op=train_op,\n",
    "        eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\aqwis\\AppData\\Local\\Temp\\tmpzjjpm0ug\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\aqwis\\\\AppData\\\\Local\\\\Temp\\\\tmpzjjpm0ug', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027EED904550>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build the Estimator\n",
    "model = tf.estimator.Estimator(model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\aqwis\\AppData\\Local\\Temp\\tmpzjjpm0ug\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 2.708302024091001, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 159.638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0790762588475873, step = 100 (0.628 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 270.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5666225976456971, step = 200 (0.366 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 302.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.5770552325108325, step = 300 (0.331 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 326.527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.6496171848210093, step = 400 (0.306 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 344.005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.46790161777462846, step = 500 (0.290 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 321.329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.25322334545637093, step = 600 (0.311 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 296.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.3086754685140326, step = 700 (0.338 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 343.447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.41178990047368647, step = 800 (0.291 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 327.651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.24531774834118036, step = 900 (0.305 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\aqwis\\AppData\\Local\\Temp\\tmpzjjpm0ug\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 0.3768066034131845.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x27eed9042e8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Model\n",
    "model.train(input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-05-08-12:35:08"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\aqwis\\AppData\\Local\\Temp\\tmpzjjpm0ug\\model.ckpt-1000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-05-08-12:35:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.8737864, global_step = 1000, loss = 0.36327505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8737864, 'global_step': 1000, 'loss': 0.36327505}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "\n",
    "#process test data\n",
    "biomag_labeled_1['y_test'] = np.reshape(biomag_labeled_1['y_test'],206)\n",
    "biomag_labeled_1['y_test'] = biomag_labeled_1['y_test']-1\n",
    "# Define the input function for evaluating\n",
    "input_fn_test = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={'train_data': biomag_labeled_1['x_test']}, y=biomag_labeled_1['y_test'],\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "# Use the Estimator 'evaluate' method\n",
    "model.evaluate(input_fn_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomag_labeled_1['y_train'].shape\n",
    "\n",
    "biomag_labeled_1['y_train'] = biomag_labeled_1['y_train'].T\n",
    "\n",
    "biomag_labeled_1['y_train'] = np.reshape(biomag_labeled_1['y_train'],2094)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomag_labeled_1['y_test'] = np.reshape(biomag_labeled_1['y_test'],206)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biomag_labeled_1['y_test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This application is used to convert notebook files (*.ipynb) to various other\nformats.\n\nWARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n\nOptions\n\n-------\n\n\n\nArguments that take values are actually convenience aliases to full\nConfigurables, whose aliases are listed on the help line. For more information\non full configurables, see '--help-all'.\n\n\n--debug\n\n    set log level to logging.DEBUG (maximize logging output)\n\n--generate-config\n\n    generate default config file\n\n-y\n\n    Answer yes to any questions instead of prompting.\n\n--execute\n\n    Execute the notebook prior to export.\n\n--allow-errors\n\n    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n\n--stdin\n\n    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n\n--stdout\n\n    Write notebook output to stdout instead of files.\n\n--inplace\n\n    Run nbconvert in place, overwriting the existing notebook (only \n    relevant when converting to notebook format)\n\n--clear-output\n\n    Clear output of current file and save in place, \n    overwriting the existing notebook.\n\n--no-prompt\n\n    Exclude input and output prompts from converted document.\n--log-level=<Enum> (Application.log_level)\n\n    Default: 30\n\n    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')\n\n    Set the log level by value or name.\n\n--config=<Unicode> (JupyterApp.config_file)\n\n    Default: ''\n\n    Full path of a config file.\n\n--to=<Unicode> (NbConvertApp.export_format)\n\n    Default: 'html'\n\n    The export format to be used, either one of the built-in formats, or a\n\n    dotted object name that represents the import path for an `Exporter` class\n\n--template=<Unicode> (TemplateExporter.template_file)\n\n    Default: ''\n\n    Name of the template file to use\n\n--writer=<DottedObjectName> (NbConvertApp.writer_class)\n\n    Default: 'FilesWriter'\n\n    Writer class used to write the  results of the conversion\n\n--post=<DottedOrNone> (NbConvertApp.postprocessor_class)\n\n    Default: ''\n\n    PostProcessor class used to write the results of the conversion\n\n--output=<Unicode> (NbConvertApp.output_base)\n\n    Default: ''\n\n    overwrite base name use for output files. can only be used when converting\n\n    one notebook at a time.\n\n--output-dir=<Unicode> (FilesWriter.build_directory)\n\n    Default: ''\n\n    Directory to write output(s) to. Defaults to output to the directory of each\n\n    notebook. To recover previous default behaviour (outputting to the current\n\n    working directory) use . as the flag value.\n\n--reveal-prefix=<Unicode> (SlidesExporter.reveal_url_prefix)\n\n    Default: ''\n\n    The URL prefix for reveal.js. This can be a a relative URL for a local copy\n\n    of reveal.js, or point to a CDN.\n\n    For speaker notes to work, a local reveal.js prefix must be used.\n\n--nbformat=<Enum> (NotebookExporter.nbformat_version)\n\n    Default: 4\n\n    Choices: [1, 2, 3, 4]\n\n    The nbformat version to write. Use this to downgrade notebooks.\n\nTo see all available configurables, use `--help-all`\n\nExamples\n--------\n\n    The simplest way to use nbconvert is\n    \n    > jupyter nbconvert mynotebook.ipynb\n    \n    which will convert mynotebook.ipynb to the default format (probably HTML).\n    \n    You can specify the export format with `--to`.\n    Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides']\n    \n    > jupyter nbconvert --to latex mynotebook.ipynb\n    \n    Both HTML and LaTeX support multiple output templates. LaTeX includes\n    'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n    can specify the flavor of the format used.\n    \n    > jupyter nbconvert --to html --template basic mynotebook.ipynb\n    \n    You can also pipe the output to stdout, rather than a file\n    \n    > jupyter nbconvert mynotebook.ipynb --stdout\n    \n    PDF is generated via latex\n    \n    > jupyter nbconvert mynotebook.ipynb --to pdf\n    \n    You can get (and serve) a Reveal.js-powered slideshow\n    \n    > jupyter nbconvert myslides.ipynb --to slides --post serve\n    \n    Multiple notebooks can be given at the command line in a couple of \n    different ways:\n    \n    > jupyter nbconvert notebook*.ipynb\n    > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n    \n    or you can specify the notebooks list in a config file, containing::\n    \n        c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n    \n    > jupyter nbconvert --config mycfg.py\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] WARNING | pattern 'baseline_ann_2.ipynb' matched no files\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script baseline_ann_2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
